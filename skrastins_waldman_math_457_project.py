# -*- coding: utf-8 -*-
"""Skrastins_Waldman_MATH-457-Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lWU0_sP1hvGjsItutnXEcMgsTr9uvqOg
"""

import pandas as pd
import csv
import matplotlib.pyplot as plt
from matplotlib.pyplot import subplots
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (recall_score, f1_score, precision_score, mean_squared_error, accuracy_score, confusion_matrix)
from sklearn.model_selection import (train_test_split, cross_val_score,
                                     KFold, GridSearchCV)
from sklearn.tree import DecisionTreeClassifier as DTC
from sklearn.tree import plot_tree
from sklearn.ensemble import (BaggingClassifier, GradientBoostingClassifier)
import seaborn as sns
from sklearn.decomposition import PCA

#Load in data
preg_df = pd.read_csv("Maternal Health Risk Data Set.csv", low_memory=False)

#Look at dataframe to ensure everything looks ok
preg_df.head()

count = (preg_df["RiskLevel"] == "high risk").sum()
count2 = (preg_df["RiskLevel"] == "mid risk").sum()
count3 = (preg_df["RiskLevel"] == "low risk").sum()
print("high risk = ", count) # 26.9%
print("mid risk = ", count2) # 33.1%
print("low risk = ", count3) # 40.0%

#Split the dataframe into X2_train, X2_test, y2_train, y2_test

X2 = preg_df.drop(columns=['RiskLevel'])
y2 = preg_df['RiskLevel']
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.2, random_state = 42)

#Replace the classes (low risk, mid risk, and high risk) with 0,1, and 2, for ease of metric
# calculations

y2_train = y2_train.replace({'low risk': 0, 'mid risk': 1, 'high risk': 2})
y2_test = y2_test.replace({'low risk': 0, 'mid risk': 1, 'high risk': 2})

#Create a Benchmark Logistic Regression model, to asses whether or not their is a relationship
#between X and y

model2 = LogisticRegression(max_iter=10000)
model2.fit(X2_train, y2_train)
y2_pred = model2.predict(X2_test)
accuracy = accuracy_score(y2_test, y2_pred)
print(f"Accuracy: {accuracy}")

#For LR visualization purposes ONLY!!! (Not actual model)

#We're selecting one predictor, Blood Sugar, and keeping the others constant (taking their average)
#This way, we can plot LR

feature_to_vary = 'BS'

diastolic_range = np.linspace(X2_test[feature_to_vary].min(), X2_test[feature_to_vary].max(), 300)

fixed_features = X2_test.mean(axis=0).to_numpy()
fixed_features = np.tile(fixed_features, (diastolic_range.shape[0], 1))

fixed_features[:, X2_test.columns.get_loc(feature_to_vary)] = diastolic_range

y_pred_proba = model2.predict_proba(fixed_features)

plt.figure(figsize=(8, 6))

plt.plot(diastolic_range, y_pred_proba[:, 0], color='blue', label="Low Risk (0)")
plt.plot(diastolic_range, y_pred_proba[:, 1], color='green', label="Mid Risk (1)")
plt.plot(diastolic_range, y_pred_proba[:, 2], color='red', label="High Risk (2)")


plt.xlabel('Blood Sugar')
plt.ylabel(r'$P(y \in \text{class}_i | X = Blood\ Sugar), \quad \text{where } i = 0, 1, 2$')
plt.title('Plot of Logistic Regression Model, with $X = X_{0}$ = Blood Sugar and where $X_{1},...,X_{N}$ are Averaged')
plt.legend()

plt.show()

#Let's test PCA to see if our model will overfit. If the accuracy decreases, our model is prone to overfitting

pca2 = PCA(n_components=4)
X2_train_PCA = pca2.fit_transform(X2_train)
X2_test_PCA = pca2.fit_transform(X2_test)

model2.fit(X2_train_PCA, y2_train)
y2_pred = model2.predict(X2_test_PCA)

accuracy = accuracy_score(y2_test, y2_pred)
print(f"Accuracy: {accuracy}") #Got waayyyyyy worse

#Let's test Ridge Regression as well. If our LR model is overfit, this should help

model2 = LogisticRegression(penalty = 'l2', max_iter=10000) #C = 0.01 made it worse, 0.1 made no difference
model2.fit(X2_train, y2_train)

y2_pred = model2.predict(X2_test)

accuracy = accuracy_score(y2_test, y2_pred)
print(f"Accuracy: {accuracy}")

#And let's test Lasso Regression

L1model2 = LogisticRegression(penalty = 'l1', solver='liblinear', max_iter=10000) #C=0.01 makes it worse
L1model2.fit(X2_train, y2_train)

y2_pred = L1model2.predict(X2_test)

accuracy = accuracy_score(y2_test, y2_pred)
print(f"Accuracy: {accuracy}")

#This is a tree depth finder. This prevents overfitting

param_grid = {
    'max_depth': range(1, 21)
}

tree_model = DTC(random_state=42)

kfold = KFold(n_splits=10, random_state=1, shuffle=True)

grid_search = GridSearchCV(estimator=tree_model,
                           param_grid=param_grid,
                           cv=kfold,
                           scoring='accuracy',
                           refit=True)

grid_search.fit(X2_train, y2_train)

best_max_depth = grid_search.best_params_['max_depth']
print(f"Best max_depth: {best_max_depth}")

best_model = grid_search.best_estimator_
test_accuracy = best_model.score(X2_test, y2_test)
print(f"Test Accuracy: {test_accuracy}")

#This is a maximum nodes finder. This also prevent overfitting

ccp_path = tree_model.cost_complexity_pruning_path(X2_train, y2_train)
ccp_alphas = ccp_path.ccp_alphas
kfold = KFold(10, random_state=1, shuffle=True)

grid = GridSearchCV(estimator=tree_model,
                        param_grid={'ccp_alpha': ccp_alphas},
                        refit=True,
                        cv=kfold,
                        scoring='neg_mean_squared_error')
grid.fit(X2_train, y2_train)

best_ = grid.best_estimator_
print("Number of nodes in best tree = ", best_.tree_.node_count)

#Fit a tree with the max_depth!

tree_model = DTC(random_state=42, max_depth = 17)
tree_model.fit(X2_train, y2_train)
y_pred = tree_model.predict(X2_test)

accuracy = accuracy_score(y2_test, y_pred)
print(f"Accuracy: {accuracy}")

#This finds the most important features. Very helpful for interpretation
feature_names = X2.columns.tolist()
feature_imp = pd.DataFrame(
    {'importance':tree_model.feature_importances_}, index = feature_names)
feature_imp.sort_values(by='importance', ascending=False)

from matplotlib import pyplot as plt
_df_1['importance'].plot(kind='line', figsize=(8, 4), title = 'Importance of Predictors in the Boosted Tree Model')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.gca().set_xlabel('Predictor')
plt.gca().set_ylabel('Percentage of Input the Predictor Contributes')
plt.show()

#Let's visualize the tree!

ax = subplots(figsize=(12,12))[1]
plot_tree(tree_model, max_depth = 17, filled = True, feature_names = ('Age', 'SystolicBP',	'DiastolicBP', 'BS',	'BodyTemp',	'HeartRate',	'RiskLevel'),
          ax=ax);

#A zoom in on the tree to see what it's actually doing

ax = subplots(figsize=(12,12))[1]
plot_tree(tree_model, max_depth = 3, filled = True, feature_names = ('Age', 'SystolicBP',	'DiastolicBP', 'BS',	'BodyTemp',	'HeartRate',	'RiskLevel'),
          ax=ax);

#Now, let's create the baseline boost model ~ this model's hyperparameters have not been tuned

boost_model1 = GradientBoostingClassifier(n_estimators=1500, max_depth=17, learning_rate=0.1)

boost_model1.fit(X2_train, y2_train)
pred = boost_model1.predict(X2_test)

accuracy = accuracy_score(y2_test, pred)
print(f"Accuracy: {accuracy}")

#This is a custome Hyperparameter finder! Note that although an accuracy score of ~84% appears below, when the hyperparameters
#are plugged into the GradientBoostingClassifier, an accuracy score of ~83% is achieved

learn_rates = [0.001, 0.01, 0.1, 1]
estimators = [900, 1000, 1250, 1500, 1750, 2000]

purr = []

for i in learn_rates:
    for j in estimators:

        boost_model = GradientBoostingClassifier(n_estimators=j, max_depth=17, learning_rate=i)
        boost_model.fit(X2_train, y2_train)
        pred = boost_model.predict(X2_test)
        accuracy = accuracy_score(y2_test, pred)

        temp = [accuracy, j, i]
        purr.append(temp)

for result in purr:
    print(f"Accuracy: {result[0]}, Estimators: {result[1]}, Learning Rate: {result[2]}")

#Let's make another Boosted tree mode, but with the optimal hyperparameters

boost_model2 = GradientBoostingClassifier(n_estimators=1500, max_depth=17, learning_rate=0.01)

boost_model2.fit(X2_train, y2_train)
pred_boost_model2 = boost_model2.predict(X2_test)

accuracy = accuracy_score(y2_test, pred_boost_model2)
print(f"Accuracy: {accuracy}")

# Perform K-Fold cross validation.
kf = KFold(n_splits= 10, shuffle= True, random_state=42)

scores = cross_val_score(estimator = boost_model2, X=X2, y = y2, scoring = 'accuracy', cv = kf)

print("Cross-validation scores:", scores)
print("Mean accuracy:", scores.mean())
print("Standard deviation of accuracy:", scores.std())

#This is a confusion matrix to help us visualize how well our model is performing

cm = confusion_matrix(y2_test, pred_boost_model2)

plt.figure(figsize=(10, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted low risk (0)', 'Predicted mid risk (1)', 'Predicted high risk (2)'], yticklabels=['Actual low risk (0)', 'Actual mid risk (1)', 'Actual high risk (2)'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix of Boosted Tree Model Predictions')
plt.show()

#Additional metrics

accuracy = accuracy_score(y2_test, pred_boost_model2)
print(f"Accuracy: {accuracy}")

precision = precision_score(y2_test, pred_boost_model2, average='macro')
print(f"Precision: {precision}")

test_error_1 = 1 - accuracy
print(f"Test Error 1: {test_error_1}")

test_error_2 = 1 - precision
print(f"Test Error 2: {test_error_2}")

recall = recall_score(y2_test, pred_boost_model2, average=None)
print(f"Recall for each class: {recall}")

f1 = f1_score(y2_test, pred_boost_model2, average='macro')
print(f"F1 Score: {f1:.4f}")